Authors;Title;Year;Source title;Volume;Issue;Art. No.;Page start;Page end;Page count;Cited by;Link;Abstract;Domain
Turel O., Kapoor B.;A business analytics maturity perspective on the gap between business schools and presumed industry needs;2016;Communications of the Association for Information Systems;39;1;;96;109;;3;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978517789&partnerID=40&md5=26884d187d028e832b17faa1a86df88e;Business analytics is a fast-growing job market for business school graduates. Hence, researchers have made many calls to enhance business analytics training in business schools to meet the growing market demand for analyticssavvy employees. A growing set of business analytics courses have begun to address these calls. In this paper, we examine the maturity of business analytics offerings in business schools in the United States by analyzing current business analytics-related course offerings of the top 104 business schools (363 courses) and 20 unranked business schools (51 courses) in the United States. We analyze these data by examining the types of courses offered and rank the schools based on their maturity levels in terms of business analytics offerings. Our findings indicate that, to the extent that these schools reflect what is happening across the nation, business schools still have a long way to go before they reach higher levels of business analytics maturity and that they are not yet in an ideal position to serve the presumed industry needs. We offer actionable recommendations. © 2016 by the Association for Information Systems.;
Jones S., Cournane S., Sheehy N., Hederman L.;A Business Analytics Software Tool for Monitoring and Predicting Radiology Throughput Performance;2016;Journal of Digital Imaging;29;6;;645;653;;2;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960099171&doi=10.1007%2fs10278-016-9871-3&partnerID=40&md5=8239b00e8979aa730674dcf208b91c2f;Business analytics (BA) is increasingly being utilised by radiology departments to analyse and present data. It encompasses statistical analysis, forecasting and predictive modelling and is used as an umbrella term for decision support and business intelligence systems. The primary aim of this study was to determine whether utilising BA technologies could contribute towards improved decision support and resource management within radiology departments. A set of information technology requirements were identified with key stakeholders, and a prototype BA software tool was designed, developed and implemented. A qualitative evaluation of the tool was carried out through a series of semi-structured interviews with key stakeholders. Feedback was collated, and emergent themes were identified. The results indicated that BA software applications can provide visibility of radiology performance data across all time horizons. The study demonstrated that the tool could potentially assist with improving operational efficiencies and management of radiology resources. © 2016, Society for Imaging Informatics in Medicine.;
Ryan J., Lewis C., Doster B., Daily S.;A business process management approach to perioperative supplies/instrument inventory and workflow;2014;Proceedings of the Annual Hawaii International Conference on System Sciences;;;6758959;2868;2877;;3;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84902269158&doi=10.1109%2fHICSS.2014.359&partnerID=40&md5=fdf463a434079e8f3cc791189b4ea08b;This study examines business process management practices applied to monitor, measure, and improve a hospital's perioperative supply workflow and corresponding inventory management. This paper identifies how dynamic technological activities of analysis, evaluation, and synthesis applied to internal and external organizational data can highlight complex relationships within integrated hospital processes to target opportunities for improvement and ultimately yield improved process capabilities. The identification of existing limitations, potential capabilities, and the subsequent contextual understanding are contributing factors that yield measured improvement within a hospital's perioperative process. Based on a 10-year longitudinal study of a large 909 registered-bed teaching hospital, this case study investigates the impact of integrated information systems to identify, qualify, and quantify business analytics used to improve perioperative efficiency and effectiveness across patient quality of care, operational efficiency, and financial cost effectiveness. The theoretical and practical implications and/or limitations of this study's results are also discussed with respect to practitioners and researchers alike. © 2014 IEEE.;
?gerstrand M., Christiansen S., Hanberg A., Rudén C., Andersson L., Andersen S., Appelgren H., Bj?rge C., Clausen I.H., Eide D.M., Hartmann N.B., Hus?y T., Halldórsson H.P., van der Hagen M., Ingre-Khans E., Lillicrap A.D., Beltoft V.M., Mörk A.-K., Murtomaa-Hautala M., Nielsen E., Ólafsdóttir K., Palomäki J., Papponen H., Reiler E.M., Stockmann-Juvala H., Suutari T., Tyle H., Beronius A.;A call for action: Improve reporting of research studies to increase the scientific basis for regulatory decision-making;2018;Journal of Applied Toxicology;38;5;;783;785;;;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040020579&doi=10.1002%2fjat.3578&partnerID=40&md5=7995b62a731c2e3266de62dd1699ae8f;This is a call for action to scientific journals to introduce reporting requirements for toxicity and ecotoxicity studies. Such reporting requirements will support the use of peer-reviewed research studies in regulatory decision-making. Moreover, this could improve the reliability and reproducibility of published studies in general and make better use of the resources spent in research. © 2018 The Authors. Journal of Applied Toxicology published by John Wiley & Sons Ltd.;
Relich M., Pawlewski P.;A case-based reasoning approach to cost estimation of new product development;2018;Neurocomputing;272;;;40;45;;3;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021283390&doi=10.1016%2fj.neucom.2017.05.092&partnerID=40&md5=7cbf1286d4f370633fcc6bec0ccbed6c;New product development (NPD) is a crucial process in maintaining a company's competitive position and succeeding in dynamic markets. One of contemporary trends in the global economy is mass customisation that bases on modifications of existing products instead of designing everything anew. The advancement of information technology helps today's enterprises in managing business processes and collecting data in enterprise systems that can be a potential source of information. Specifications of previous products deliver information of design, cost and time of past NPD projects that can be the basis for developing new products. A promising methodology for assisting conceptual product design and monitoring a NPD project is case-based reasoning. This paper is concerned with developing a case-based reasoning approach towards using neural networks to estimate the cost of NPD in one-of-a-kind production companies. © 2017 Elsevier B.V.;
Cohen A., Parsons S., Sklar E.I., McBurney P.;A characterization of types of support between structured arguments and their relationship with support in abstract argumentation;2018;International Journal of Approximate Reasoning;94;;;76;104;;;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041473266&doi=10.1016%2fj.ijar.2017.12.008&partnerID=40&md5=f50174b612adfe364a1d397af87bc117;"Argumentation is an important approach in artificial intelligence and multiagent systems, providing a basis for single agents to make rational decisions, and for groups of agents to reach agreements, as well as a mechanism to underpin a wide range of agent interactions. In such work, a crucial role is played by the notion of attack between arguments, and the notion of attack is well-studied. There is, for example, a range of different approaches to identifying which of a set of arguments should be accepted given the attacks between them. Less well studied is the notion of support between arguments, yet the idea that one argument may support another is very intuitive and seems particularly relevant in the area of decision-making where decision options may have multiple arguments for and against them. In the last decade, the study of support in argumentation has regained attention among researchers, but most approaches address support in the context of abstract argumentation where the elements from which arguments are composed are ignored. In contrast, this paper studies the notion of support between arguments in the context of structured argumentation systems where the elements from which arguments are composed play a crucial role. Different forms of support are presented, each of which takes into account the structure of arguments; and the relationships between these forms of support are studied. Then, the paper investigates whether there is a correspondence between the structured and abstract forms of support, and determines whether the abstract formalisms may be instantiated using concrete forms of support in terms of structured arguments. The conclusion is that support in structured argumentation does not mesh well with support in abstract argumentation, and this suggests that more work is required to develop forms of support in abstract argumentation that model what happens in structured argumentation. © 2018 Elsevier Inc.";
Nguyen T.N., Ricci F.;A chat-based group recommender system for tourism;2018;Information Technology and Tourism;18;43469;;5;28;;;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045104130&doi=10.1007%2fs40558-017-0099-y&partnerID=40&md5=fbb9263bac80a3ea658ca69e9027441d;Group recommender systems are information filtering and decision support applications that are aimed at aiding a group of users in making decisions when they are considering a set of alternatives. State of the art solutions aggregate users’ preferences acquired before the actual decision making process and suggest items that fit the aggregated model. However, it has been shown that the recommendation needs of groups go beyond the identification of such items, and it is essential to take into account, in the recommendation process, the dynamic of users’ interactions in their real group context. In this paper, we therefore illustrate a novel approach to group recommendation, which is implemented in a mobile system, that monitors and exploits users’ interactions during a group discussion, and offers appropriate recommendations as well as other types of suggestions, to guide and help the group members in settling on an agreement. We have carried out a preliminary user study of the proposed approach to assess and analyze the usability of the system along with the perceived recommendation quality and choice satisfaction. The results of this study are encouraging as they show that the proposed approach attains a high usability score, and has good user-perceived recommendation quality as well as choice satisfaction. © 2017, Springer-Verlag GmbH Germany, part of Springer Nature.;
Mohajeri N., Assouline D., Guiboud B., Bill A., Gudmundsson A., Scartezzini J.-L.;A city-scale roof shape classification using machine learning for solar energy applications;2018;Renewable Energy;121;;;81;93;;1;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040325135&doi=10.1016%2fj.renene.2017.12.096&partnerID=40&md5=f51e5d09bbcb1a8da262c787e7a9b0f1;Solar energy deployment through PV installations in urban areas depends strongly on the shape, size, and orientation of available roofs. Here we use a machine learning approach, Support Vector Machine (SVM) classification, to classify 10,085 building roofs in relation to their received solar energy in the city of Geneva in Switzerland. The SVM correctly identifies six types of roof shapes in 66% of cases, that is, flat & shed, gable, hip, gambrel & mansard, cross/corner gable & hip, and complex roofs. We classify the roofs based on their useful area for PV installations and potential for receiving solar energy. For most roof shapes, the ratio between useful roof area and building footprint area is close to one, suggesting that footprint is a good measure of useful PV roof area. The main exception is the gable where this ratio is 1.18. The flat and shed roofs have the second highest useful roof area for PV (complex roof being the highest) and the highest PV potential (in GWh). By contrast, hip roof has the lowest PV potential. Solar roof-shape classification provides basic information for designing new buildings, retrofitting interventions on the building roofs, and efficient solar integration on the roofs of buildings. © 2017 Elsevier Ltd;
Tsai C.-F., Li M.-L., Lin W.-C.;A class center based approach for missing value imputation;2018;Knowledge-Based Systems;151;;;124;135;;;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046998800&doi=10.1016%2fj.knosys.2018.03.026&partnerID=40&md5=d8eed12f850680a1b459a33f0662f3c1;Missing value imputation (MVI) is the major solution method for dealing with incomplete dataset problems in which the missing attribute values are replaced from a chosen set of observed data using some statistical methods, such as mean/mode, machine learning, or support vector machine methods. Although machine learning MVI approaches may produce reasonably good imputation results, they usually require larger imputation times than statistical approaches. In this paper, a Class Center based Missing Value Imputation (CCMVI) approach is introduced for producing effective imputation results more efficiently. It is based on measuring the class center of each class and then the distances between it and the other observed data are used to define a threshold for the later imputation. The experimental results based on numerical, categorical, and mixed data types of datasets show that the proposed CCMVI approach outperforms the other MVI approaches for both numerical and mixed datasets. In addition, it requires much less imputation time than the machine learning MVI methods. © 2018 Elsevier B.V.;
Yang C.-Y., Lo Y.-S., Chen R.-J., Liu C.-T.;A clinical decision support engine based on a national medication repository for the detection of potential duplicate medications: Design and evaluation;2018;Journal of Medical Internet Research;20;1; e6;;;;;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041036293&doi=10.2196%2fmedinform.9064&partnerID=40&md5=2f8f878e1caa13fb655f228d77bc8134;Background: A computerized physician order entry (CPOE) system combined with a clinical decision support system can reduce duplication of medications and thus adverse drug reactions. However, without infrastructure that supports patients' integrated medication history across health care facilities nationwide, duplication of medication can still occur. In Taiwan, the National Health Insurance Administration has implemented a national medication repository and Web-based query system known as the PharmaCloud, which allows physicians to access their patients' medication records prescribed by different health care facilities across Taiwan. Objective: This study aimed to develop a scalable, flexible, and thematic design-based clinical decision support (CDS) engine, which integrates a national medication repository to support CPOE systems in the detection of potential duplication of medication across health care facilities, as well as to analyze its impact on clinical encounters. Methods: A CDS engine was developed that can download patients' up-To-date medication history from the PharmaCloud and support a CPOE system in the detection of potential duplicate medications. When prescribing a medication order using the CPOE system, a physician receives an alert if there is a potential duplicate medication. To investigate the impact of the CDS engine on clinical encounters in outpatient services, a clinical encounter log was created to collect information about time, prescribed drugs, and physicians' responses to handling the alerts for each encounter. Results: The CDS engine was installed in a teaching affiliate hospital, and the clinical encounter log collected information for 3 months, during which a total of 178,300 prescriptions were prescribed in the outpatient departments. In all, 43,844/178,300 (24.59%) patients signed the PharmaCloud consent form allowing their physicians to access their medication history in the PharmaCloud. The rate of duplicate medication was 5.83% (1843/31,614) of prescriptions. When prescribing using the CDS engine, the median encounter time was 4.3 (IQR 2.3-7.3) min, longer than that without using the CDS engine (median 3.6, IQR 2.0-6.3 min). From the physicians' responses, we found that 42.06% (1908/4536) of the potential duplicate medications were recognized by the physicians and the medication orders were canceled. Conclusions: The CDS engine could easily extend functions for detection of adverse drug reactions when more and more electronic health record systems are adopted. Moreover, the CDS engine can retrieve more updated and completed medication histories in the PharmaCloud, so it can have better performance for detection of duplicate medications. Although our CDS engine approach could enhance medication safety, it would make for a longer encounter time. This problem can be mitigated by careful evaluation of adopted solutions for implementation of the CDS engine. The successful key component of a CDS engine is the completeness of the patient's medication history, thus further research to assess the factors in increasing the PharmaCloud consent rate is required.;
Calcaterra D., Di Modica G., Tomarchio O., Romeo P.;A clinical decision support system to increase appropriateness of diagnostic imaging prescriptions;2018;Journal of Network and Computer Applications;117;;;17;29;;;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047617315&doi=10.1016%2fj.jnca.2018.05.011&partnerID=40&md5=e066c747ea71493782ef286fbe13d800;The use of diagnostic imaging procedures has significantly risen in the last decade. However, several studies estimate that a substantial number of requests for diagnostic imaging are inappropriate, leading to unnecessary exposure to radiation, increased wait times, and ineffective use of health care resources. Although many radiology societies from all over the world have published imaging referral guidelines which general practitioners should follow when ordering imaging examinations, the uptake by practitioners is still far from being considered realized nor are the guidelines well integrated in the clinical workflows. In this paper we present a Clinical Decision Support System (CDSS) that provides physicians with real-time guidance to prescribe patients appropriate diagnostic imaging tests. The CDDS embeds the imaging referral guidelines in the form of coded rules that help the physicians in their prescription work. It also provides tools that promote the collaboration among physicians and radiologists in the diagnostic process. The work has been carried out in a recently ended research project which investigated the phenomenon of inappropriate imaging prescribing in Sicily, Italy. Results from a field experimentation show a high potential impact of the CDSS in reducing inappropriate imaging. © 2018 Elsevier Ltd;
Calcaterra D., Di Modica G., Tomarchio O., Romeo P.;A clinical decision support system to increase appropriateness of diagnostic imaging prescriptions;2018;Journal of Network and Computer Applications;117;;;17;29;;;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047617315&doi=10.1016%2fj.jnca.2018.05.011&partnerID=40&md5=e066c747ea71493782ef286fbe13d800;The use of diagnostic imaging procedures has significantly risen in the last decade. However, several studies estimate that a substantial number of requests for diagnostic imaging are inappropriate, leading to unnecessary exposure to radiation, increased wait times, and ineffective use of health care resources. Although many radiology societies from all over the world have published imaging referral guidelines which general practitioners should follow when ordering imaging examinations, the uptake by practitioners is still far from being considered realized nor are the guidelines well integrated in the clinical workflows. In this paper we present a Clinical Decision Support System (CDSS) that provides physicians with real-time guidance to prescribe patients appropriate diagnostic imaging tests. The CDDS embeds the imaging referral guidelines in the form of coded rules that help the physicians in their prescription work. It also provides tools that promote the collaboration among physicians and radiologists in the diagnostic process. The work has been carried out in a recently ended research project which investigated the phenomenon of inappropriate imaging prescribing in Sicily, Italy. Results from a field experimentation show a high potential impact of the CDSS in reducing inappropriate imaging. © 2018 Elsevier Ltd;
Gaw N., Schwedt T.J., Chong C.D., Wu T., Li J.;A clinical decision support system using multi-modality imaging data for disease diagnosis;2018;IISE Transactions on Healthcare Systems Engineering;8;1;;36;46;;1;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038623725&doi=10.1080%2f24725579.2017.1403520&partnerID=40&md5=f7949f1b1d083c0adf5333c02f149f35;"Readily available imaging technologies have made it possible to acquire multiple imaging modalities with complementary information for the same patient. These imaging modalities describe different properties about the organ of interest, providing an opportunity for better diagnosis, staging and treatment assessments. However, existing research in combining multi-modality imaging data has not been transformed into a clinical decision support system due to lack of flexibility, accuracy, and interpretability. This article proposes a multi-modality imaging-based diagnostic decision support system (MMI-DDS) that overcomes limitations of existing research. MMI-DDS includes three inter-connected components: (1) a modality-wise principal component analysis (PCA) that reduces data dimensionality and eliminates the need for co-registration of multi-modality images; (2) a novel constrained particle swarm optimization (cPSO) classifier that is built upon the joint set of the principal components (PCs) from all of the imaging modalities; (3) a clinical utility engine that employs inverse operations to identify contributing imaging features (a.k.a. biomarkers) in diagnosing the disease. To validate MMI-DDS, we apply it to a migraine dataset with multi-modality structural and functional magnetic resonance imaging (MRI) data. MMI-DDS shows significantly improved diagnostic accuracy than using single imaging modalities alone and also identifies biomarkers that are consistent with findings in migraine literature. © 2018 “IISE”.";
Karlsson L.O., Nilsson S., B?ng M., Nilsson L., Charitakis E., Janzon M.;A clinical decision support tool for improving adherence to guidelines on anticoagulant therapy in patients with atrial fibrillation at risk of stroke: A cluster-randomized trial in a Swedish primary care setting (the CDS-AF study);2018;PLoS Medicine;15;3; e1002528;;;;1;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045620091&doi=10.1371%2fjournal.pmed.1002528&partnerID=40&md5=abc0130e6a88685b724cb0c90f750ef3;"Background: Atrial fibrillation (AF) is associated with substantial morbidity, in particular stroke. Despite good evidence for the reduction of stroke risk with anticoagulant therapy, there remains significant undertreatment. The main aim of the current study was to investigate whether a clinical decision support tool (CDS) for stroke prevention integrated in the electronic health record could improve adherence to guidelines for stroke prevention in patients with AF. Methods and findings: We conducted a cluster-randomized trial where all 43 primary care clinics in the county of Östergötland, Sweden (population 444,347), were randomized to be part of the CDS intervention or to serve as controls. The CDS produced an alert for physicians responsible for patients with AF and at increased risk for thromboembolism (according to the CHA2DS2-VASc algorithm) without anticoagulant therapy. The primary endpoint was adherence to guidelines after 1 year. After randomization, there were 22 and 21 primary care clinics in the CDS and control groups, respectively. There were no significant differences in baseline adherence to guidelines regarding anticoagulant therapy between the 2 groups (CDS group 70.3% [5,186/7,370; 95% CI 62.9%–77.7%], control group 70.0% [4,187/6,009; 95% CI 60.4%–79.6%], p = 0.83). After 12 months, analysis with linear regression with adjustment for primary care clinic size and adherence to guidelines at baseline revealed a significant increase in guideline adherence in the CDS (73.0%, 95% CI 64.6%–81.4%) versus the control group (71.2%, 95% CI 60.8%–81.6%, p = 0.013, with a treatment effect estimate of 0.016 [95% CI 0.003–0.028]; number of patients with AF included in the final analysis 8,292 and 6,508 in the CDS and control group, respectively). Over the study period, there was no difference in the incidence of stroke, transient ischemic attack, or systemic thromboembolism in the CDS group versus the control group (49 [95% CI 43–55] per 1,000 patients with AF in the CDS group compared to 47 [95% CI 39–55] per 1,000 patients with AF in the control group, p = 0.64). Regarding safety, the CDS group had a lower incidence of significant bleeding, with events in 12 (95% CI 9–15) per 1,000 patients with AF compared to 16 (95% CI 12–20) per 1,000 patients with AF in the control group (p = 0.04). Limitations of the study design include that the analysis was carried out in a catchment area with a high baseline adherence rate, and issues regarding reproducibility to other regions. Conclusions: The present study demonstrates that a CDS can increase guideline adherence for anticoagulant therapy in patients with AF. Even though the observed difference was small, this is the first randomized study to our knowledge indicating beneficial effects with a CDS in patients with AF. © 2018 Karlsson et al.";
Bjoerlykhaug E.D.;A closed loop inverse kinematics solver intended for offline calculation optimized with GA;2018;Robotics;7;1;7;;;;;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041202787&doi=10.3390%2frobotics7010007&partnerID=40&md5=3916133712a9b71ba23b5471d279841d;This paper presents a simple approach to building a robotic control system. Instead of a conventional control system which solves the inverse kinematics in real-time as the robot moves, an alternative approach where the inverse kinematics is calculated ahead of time is presented. This approach reduces the complexity and code necessary for the control system. Robot control systems are usually implemented in low level programming language. This new approach enables the use of high level programming for the complex inverse kinematics problem. For our approach, we implement a program to solve the inverse kinematics, called the Inverse Kinematics Solver (IKS), in Java, with a simple graphical user interface (GUI) to load a file with desired end effector poses and edit the configuration of the robot using the Denavit-Hartenberg (DH) convention. The program uses the closed-loop inverse kinematics (CLIK) algorithm to solve the inverse kinematics problem. As an example, the IKS was set up to solve the kinematics for a custom built serial link robot. The kinematics for the custom robot is presented, and an example of input and output files is also presented. Additionally, the gain of the loop in the IKS is optimized using a GA, resulting in almost a 50% decrease in computational time. © 2018 by the authors.;
Dai W., Riliskis L., Wang P., Vyatkin V., Guan X.;A Cloud-Based Decision Support System for Self-Healing in Distributed Automation Systems Using Fault Tree Analysis;2018;IEEE Transactions on Industrial Informatics;14;3;;989;1000;;;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041192221&doi=10.1109%2fTII.2018.2791503&partnerID=40&md5=8d9b84dca273608e3daa490b4fead4f9;Downtime is a key performance index for industrial automation systems. An industrial automation system achieves maximum productivity when its downtime is reduced to the minimum. One approach to minimize downtime is to predict system faults and recover from them automatically. A cloud-based decision support system is proposed for rapid problem identifications and to assist the self-management processes. By running multiple parallel simulations of control software with real-time inputs ahead of system time, faults could be detected and corrected automatically using autonomous industrial software agents. Fault trees, as well as control algorithms, are modeled using IEC 61499 function blocks that can be directly executed on both physical controllers and cloud services. A case study of water heating process is used to demonstrate the self-healing process supported by the cloud-based decision support system. © 2005-2012 IEEE.;
Dai W., Riliskis L., Wang P., Vyatkin V., Guan X.;A Cloud-Based Decision Support System for Self-Healing in Distributed Automation Systems Using Fault Tree Analysis;2018;IEEE Transactions on Industrial Informatics;14;3;;989;1000;;;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041192221&doi=10.1109%2fTII.2018.2791503&partnerID=40&md5=8d9b84dca273608e3daa490b4fead4f9;Downtime is a key performance index for industrial automation systems. An industrial automation system achieves maximum productivity when its downtime is reduced to the minimum. One approach to minimize downtime is to predict system faults and recover from them automatically. A cloud-based decision support system is proposed for rapid problem identifications and to assist the self-management processes. By running multiple parallel simulations of control software with real-time inputs ahead of system time, faults could be detected and corrected automatically using autonomous industrial software agents. Fault trees, as well as control algorithms, are modeled using IEC 61499 function blocks that can be directly executed on both physical controllers and cloud services. A case study of water heating process is used to demonstrate the self-healing process supported by the cloud-based decision support system. © 2005-2012 IEEE.;
Osman I.H., Anouze A.L.;A cognitive analytics management framework (CAM-Part 2): Societal needs, shared-value models, performance indicators, big data, business analytics models and tools;2013;Handbook of Research on Strategic Performance Management and Measurement Using Data Envelopment Analysis;;;;80;189;;;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944877763&doi=10.4018%2f978-1-4666-4474-8.ch002&partnerID=40&md5=21022f091ae5434cee7cd0a93de536b1;In Chapter 1, The CAM framework focused on the development of innovative social business models through the usage of frontier data envelopment analysis to measure shared value for a sustainable growth of an organization. Chapter 2 first discusses the causes and effects of societal challenges and how shared value models can alleviate them. Second, successful technology and non-technology innovations for shared-value models are reviewed. Third, guidelines to develop key performance smart indicators, pitfalls traps, and phases of budgeting steps for the design of performance management and measurement systems are discussed. Fourth, big data and business analytics challenges, potentials, models, and tools are presented. Fifth, the essential components for designing a corporate big data strategy are suggested. Finally, new ideas are explained to democratize shared-value knowledge through electronic services to transform loyalty of people from parties, clergies, and dictatorships to society's loyalty to achieve smarter communities in the 21st century. © 2013, IGI Global.;
Osman I.H., Anouze A.L.;A cognitive analytics management framework (CAM-Part 3): Critical Skills shortage, higher education trends, education value chain framework, government strategy;2013;Handbook of Research on Strategic Performance Management and Measurement Using Data Envelopment Analysis;;;;190;234;;1;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944876046&doi=10.4018%2f978-1-4666-4474-8.ch003&partnerID=40&md5=e1b82425a441fd086919dbf62d6eaece;"The main objectives of the chapter are to evaluate the impact of the tsunami of big data, business analytics, and technology on the delivery and diffusion of knowledge around the world through the use of Internet-of-things and to design future academic education and training programs. Global and local trends are analyzed to evaluate the impact of the digital tsunami on the delivery and diffusion of knowledge; to identify the shortage of critical skills, drivers of challenges, hot skills in demand, and salaries in big data/business analytics; to highlight obstacles to make informed decisions. CAM education framework is proposed to design customized higher education and training programs to meet current shortage and future generation with the relevant and rigorous skills to boost productivity growth and to impact society and professional domains in the digital economy. Finally, new ideas on how governments, academic institutions, technology companies, and professional employers can work together to reform the traditional education value chain and integrate the ""massive open online courses"" to achieve mass diffusion of knowledge, to transform people from loyalty to parties, clergies, and dictatorships to society's loyalty, and to develop a culture of shared-value in a move towards a smarter and fairer planet in the 21st century. © 2013, IGI Global.";
Chacón-Barrantes S., López-Venegas A., Sánchez-Escobar R., Luque-Vergara N.;A Collaborative Effort Between Caribbean States for Tsunami Numerical Modeling: Case Study CaribeWave15;2018;Pure and Applied Geophysics;175;4;;1405;1428;;1;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045956673&doi=10.1007%2fs00024-017-1687-7&partnerID=40&md5=d95aa901d63cde8e46337e84f5093782;Historical records have shown that tsunami have affected the Caribbean region in the past. However infrequent, recent studies have demonstrated that they pose a latent hazard for countries within this basin. The Hazard Assessment Working Group of the ICG/CARIBE-EWS (Intergovernmental Coordination Group of the Early Warning System for Tsunamis and Other Coastal Threats for the Caribbean Sea and Adjacent Regions) of IOC/UNESCO has a modeling subgroup, which seeks to develop a modeling platform to assess the effects of possible tsunami sources within the basin. The CaribeWave tsunami exercise is carried out annually in the Caribbean region to increase awareness and test tsunami preparedness of countries within the basin. In this study we present results of tsunami inundation using the CaribeWave15 exercise scenario for four selected locations within the Caribbean basin (Colombia, Costa Rica, Panamá and Puerto Rico), performed by tsunami modeling researchers from those selected countries. The purpose of this study was to provide the states with additional results for the exercise. The results obtained here were compared to co-seismic deformation and tsunami heights within the basin (energy plots) provided for the exercise to assess the performance of the decision support tools distributed by PTWC (Pacific Tsunami Warning Center), the tsunami service provider for the Caribbean basin. However, comparison of coastal tsunami heights was not possible, due to inconsistencies between the provided fault parameters and the modeling results within the provided exercise products. Still, the modeling performed here allowed to analyze tsunami characteristics at the mentioned states from sources within the North Panamá Deformed Belt. The occurrence of a tsunami in the Caribbean may affect several countries because a great variety of them share coastal zones in this basin. Therefore, collaborative efforts similar to the one presented in this study, particularly between neighboring countries, are critical to assess tsunami hazard and increase preparedness within the countries. © 2017, Springer International Publishing AG.;
Seng K.P., Ang L.-M., Ooi C.S.;A Combined Rule-Based & Machine Learning Audio-Visual Emotion Recognition Approach;2018;IEEE Transactions on Affective Computing;9;1;;3;13;;;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043289764&doi=10.1109%2fTAFFC.2016.2588488&partnerID=40&md5=c754b4e96281c63320e03dad36fef526;This paper proposes an audio-visual emotion recognition system that uses a mixture of rule-based and machine learning techniques to improve the recognition efficacy in the audio and video paths. The visual path is designed using the Bi-directional Principal Component Analysis (BDPCA) and Least-Square Linear Discriminant Analysis (LSLDA) for dimensionality reduction and discrimination. The extracted visual features are passed into a newly designed Optimized Kernel-Laplacian Radial Basis Function (OKL-RBF) neural classifier. The audio path is designed using a combination of input prosodic features (pitch, log-energy, zero crossing rates and Teager energy operator) and spectral features (Mel-scale frequency cepstral coefficients). The extracted audio features are passed into an audio feature level fusion module that uses a set of rules to determine the most likely emotion contained in the audio signal. An audio visual fusion module fuses outputs from both paths. The performances of the proposed audio path, visual path, and the final system are evaluated on standard databases. Experiment results and comparisons reveal the good performance of the proposed system. © 2010-2012 IEEE.;
Abdelhadi M., Hamdadou D., Menni N.;A communication platform for group decision support system: Based web services and multicriteria method;2018;International Journal of E-Services and Mobile Applications;10;3;;19;41;;;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047948928&doi=10.4018%2fIJESMA.2018070102&partnerID=40&md5=b1f923e2d7d1197d6b8882161bd9f079;In a group decision support system, the various decision-makers have their own information, constrains, decision strategies, preferences, and objectives which are generally not shared or communicated. This implies that the group decision process is distributed between the different entities implicated and impacted by various group members' characteristics. Solution to this problem is to find a decision that would be acceptable to all the decision-makers, following the necessity of a negotiation process that allows the elaboration of a common agreement for a group that faces a conflict on the decision to take. In the current study, the authors propose to establish a communication platform for a group decision support system (GDSS) based on web services, incorporating a multicriteria analysis methods and a negotiation protocol. © 2018, IGI Global.;
Kolotzek C., Helbig C., Thorenz A., Reller A., Tuma A.;A company-oriented model for the assessment of raw material supply risks, environmental impact and social implications;2018;Journal of Cleaner Production;176;;;566;580;;1;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040659575&doi=10.1016%2fj.jclepro.2017.12.162&partnerID=40&md5=c1fbb79f2fb3ced8e0156ba318210b12;Since manufacturers are the main drivers in the selection of the materials used in their products, they have a special responsibility for investigating the accompanying sustainability aspects. The recently increased attention they pay to these issues is motivated not only by a sense of social responsibility, but also by pressure from customers and competitors. In particular, the three dimensions of sustainability – based on the triple bottom line of economic, environmental and social criteria – are of growing importance for sustainable supply chain management. Raw materials and their supply chains are often at the focus of attention, since manufacturers may need to diversify them for their products. Appropriate assessment models then become essential. Although raw material assessments and raw material-focused decision support schemes have recently been applied more often in the corporate context, several aspects such as indicator selection, weighting or social assessment are rarely considered. As a result, a comprehensive, sustainability-oriented raw material assessment and decision support scheme in the corporate context is not available in the scientific literature. In the design of such a scheme, four questions arise: First, how should a corporate-oriented raw material assessment model be structured? Second, how can all three sustainability dimensions be taken into account? Third, how can the application of raw material assessments in a corporate-oriented decision-making process increase the sustainability level of a company? And fourth, does a methodically structured raw material assessment model have advantages over existing models? To answer these questions, we have developed a model which takes into account state-of-the-art sustainability assessments as well as recent developments in the field of criticality analysis, life cycle impact assessment (LCIA) and social life cycle assessment (SLCA). With partners from both academia and industry we identify relevant quantitative indicators for structuring the assessment model and for calculating corresponding indicator weightings, using the analytic hierarchy process (AHP). To demonstrate the applicability of the assessment model for decision support and its benefits for companies in identifying potential hotspots in raw material supply chains, we present a case study that includes decision support for selecting capacitor technologies. A sensitivity analysis demonstrates the robustness of the assessments. In short, this article presents a sustainability-oriented raw material assessment and decision support model and proposes how it should be applied in a corporate context. © 2017 Elsevier Ltd;
Liu J., Timsina P., El-Gayar O.;A comparative analysis of semi-supervised learning: The case of article selection for medical systematic reviews;2018;Information Systems Frontiers;20;2;;195;207;;1;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84996558280&doi=10.1007%2fs10796-016-9724-0&partnerID=40&md5=91be9a1192ae51d24a101081ab792f9a;While systematic reviews are positioned as an essential element of modern evidence-based medical practice, the creation of these reviews is resource intensive. To mitigate this problem, there have been some attempts to leverage supervised machine learning to automate the article triage procedure. This approach has been proved to be helpful for updating existing systematic reviews. However, this technique holds very little promise for creating new reviews because training data is rarely available when it comes to systematic creation. In this research we assess and compare the applicability of semi-supervised learning to overcome this labeling bottleneck and support the creation of systematic reviews. The results indicated that semi-supervised learning could significantly reduce the human effort and is a viable technique for automating medical systematic review creation with a small-sized training dataset. © 2016, Springer Science+Business Media New York.;
Wang X., Yang C., Guan R.;A comparative study for biomedical named entity recognition;2018;International Journal of Machine Learning and Cybernetics;9;3;;373;382;;2;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042223524&doi=10.1007%2fs13042-015-0426-6&partnerID=40&md5=1195fe49ffa7065e167ec381ee90baa6;With high-throughput technologies applied in biomedical research, the quantity of biomedical literatures grows exponentially. It becomes more and more important to quickly as well as accurately extract knowledge from manuscripts, especially in the era of big data. Named entity recognition (NER), aiming at identifying chunks of text that refers to specific entities, is essentially the initial step for information extraction. In this paper, we will review the three models of biomedical NER and two famous machine learning methods, Hidden Markov Model and Conditional Random Fields, which have been widely applied in bioinformatics. Based on these two methods, six excellent biomedical NER tools are compared in terms of programming language, feature sets, underlying mathematical methods, post-processing techniques and flowcharts. Experimental results of these tools against two widely used corpora, GENETAG and JNLPBA, are conducted. The comparison varies from different entity types to the overall performance. Furthermore, we put forward suggestions about the selection of Bio-NER tools for different applications. © 2015, Springer-Verlag Berlin Heidelberg.;
Reuter U., Sultan A., Reischl D.S.;A comparative study of machine learning approaches for modeling concrete failure surfaces;2018;Advances in Engineering Software;116;;;67;79;;;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038020611&doi=10.1016%2fj.advengsoft.2017.11.006&partnerID=40&md5=e85421ffd61f131d9f9c1bf89adc8c5d;This study introduces an enhanced approach for concrete failure criterion, which is strongly needed for a realistic simulation of concrete behavior, by employing machine learning approaches instead of the traditional models of failure surfaces. Since the shape of concrete failure surfaces is not exactly known, a general shape function for verification purposes of the machine learning approaches is introduced. Artificial neural networks, support vector machines, and support vector regression are adapted to model realizations of this general shape function with different noise levels. After the successful fitting of these surfaces, the algorithms are employed to model the failure surface of C25 concrete starting from 88 experimental tests. The three approaches are able to fit the experimental data with low error and are compared to one another. Drucker–Prager and Bresler–Pister surfaces are solved for the same experimental data and compared with the support vector regression surface. The main advantage of machine learning approaches is that they are model-free approaches which eliminate the need of new models for new concrete types. © 2017 Elsevier Ltd;
Ouahilal M., Mohajir M.E., Chahhou M., Mohajir B.E.E.;A comparative study of predictive algorithms for business analytics and decision support systems: Finance as a case study;2016;2016 International Conference on Information Technology for Organizations Development, IT4OD 2016;;;7479258;;;;1;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978042263&doi=10.1109%2fIT4OD.2016.7479258&partnerID=40&md5=de05a1ed0fe92871fbe45b369335e08e;Stock market prediction is regarded as a challenging task of financial time-series prediction. There have been many studies using machine learning techniques in this area. A large number of successful applications have shown that regression algorithms can be very useful tools for time-series modelling and forecasting. In this paper we run a comparative study of three of these algorithms: Multiple Linear Regression, Support Vector Regression and Decision Tree Regression in order to determine their performances in term of implementing financial time series forecasts. To assess the performance of these algorithms, we have conducted experiments using L'Oréal financial dataset. The results exhibit that support vector regression produced the best forecasts. © 2016 IEEE.;
Kececi B., Derya T., Dinler E., Ic Y.T.;A comparative study of the capability of alternative mixed integer programming formulations;2018;Technological and Economic Development of Economy;24;2;;561;584;;;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019069972&doi=10.3846%2f20294913.2016.1213202&partnerID=40&md5=224f0002e457d710bf3cf75c9f1ec20e;In selecting the best mixed integer linear programming (MILP) formulation the important issue is to figure out how to evaluate the performance of each candidate formulation in terms of selected criteria. The main objective of this study is to propose a systematic approach to guide the selection of the best MILP formulation among the alternatives according to the needs of the decision maker. For this reason we consider the problem of “selecting the most appropriate MILP formulation for a certain type of decision maker” as a multi-criteria decision making problem and present an integrated AHP-TOPSIS decision making methodology to select the most appropriate formulation. As an example the proposed decision making methodology is implemented on the selection of the MILP formulations of the Capacitated Vehicle Routing Problem (CVRP). A numerical example is provided for illustrative purposes. As a result, the proposed decision model can be a tool for the decision makers (here they are the scientists, engineers and practitioners) who intend to choose the appropriate mathematical model(s) among the alternatives according to their needs on their studies. The integrated AHP-TOPSIS approach can simply be incorporated into a computer-based decision support system since it has simplicity in both computation and application. © 2017 Vilnius Gediminas Technical University (VGTU) Press.;
Srilakshmi A., Rakkini J., Sekar K.R., Manikandan R.;A comparative study on Internet of Things (IoT) and its applications in smart agriculture;2018;Pharmacognosy Journal;10;2;;260;264;;1;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041104577&doi=10.5530%2fpj.2018.2.46&partnerID=40&md5=9b1390172092ce901ae7867ba39ab6fd;Agriculture plays a vital role in country’s economy and it has an extensive contribution towards human civilization. Due to the growing expansions in sensor devices, RFID and Internet protocols the architecture of Internet of Things (IoT) has been made to support agriculture by making a Smart agriculture. This paper describes the implementation of various IoT techniques and intelligent decision support systems used in agriculture. It provides a wide review on methods and technologies like ANFIS and PLSR Model predictions, experiences in various challenges as well as further work are discussed through the review article. © 2018 Phcog.Net.;
Ozkaya U., Seyfi L.;A comparative study on parameters of leaf-shaped patch antenna using hybrid artificial intelligence network models;2018;Neural Computing and Applications;29;8;;35;45;;;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992130068&doi=10.1007%2fs00521-016-2620-1&partnerID=40&md5=74db411d4fec7d8139bab3f32ad24844;This study proposes a very compact coaxial-fed planar antenna for X band applications. The antenna design includes a tulip-shaped radiator on the FR4 dielectric substrate. The antenna parameters, such as return losses, bandwidth and operating frequency, have close relationships with patch geometry. In order to obtain desired antenna parameters for X band application, patch dimension is necessary to be optimized. In this article, four different hybrid artificial intelligence network models are suggested for optimization. These are particle swarm optimization, differential evolution, grey wolf optimizer and vortex search algorithm. Also, they are combined with artificial neural network for the purpose of estimating dimension of patch. Therefore, the comparison of different proposed algorithms is analyzed to obtain higher characteristics for antenna design. Their results are compared with each other in HFSS 13.0 software. The antenna with the most suitable return loss, bandwidth and operating frequency is selected to be used in antenna design. © 2016, The Natural Computing Applications Forum.;
Frimpon M.F., Adaku E.;A comparison of high-speed internet service in Ghana: an analytical hierarchy approach;2018;Information Technology and People;31;1;;181;198;;;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041389187&doi=10.1108%2fITP-06-2016-0143&partnerID=40&md5=5e1277d69c2b0e9224a3eee8377c7dcf;Purpose: The rising proportion of internet users in Sub-Saharan Africa and the lack of analytical techniques, as decision support systems, in choosing among alternative internet service providers (ISPs) by consumers underpin this study. The purpose of this paper is to propose an approach for evaluating high-speed internet service offered by ISPs in a sub-Saharan African country. Design/methodology/approach: Using a sample size of 150, pairwise comparisons of two ISPs along five criteria of cost, usability, support, reliability and speed were performed by ten person groups of university students working in various organizations in Ghana and undertaking an online Six Sigma Course. Geometric means were employed to aggregate the scores in 15 groups, and these scores were then normalized and used as input into an analytical hierarchy process grid. Findings: The results show that consumers of internet services highly emphasize the cost attribute of internet provision in their decision making. On the other hand, it was realized that consumers least emphasize the support provided by ISPs in their decision making among alternative ISPs. Originality/value: This study has sought to provide an analytical framework for assessing the quality of service provided by alternative ISPs in a developing economy’s context. The evaluating criteria in this framework also reveal the key consumer requirements in internet service provision in a developing economy’s environment. This, to a large extent, will inform the marketing strategies of existing ISPs in Ghana as well as prospective ones intending to enter the Ghanaian market. Besides, the National Communication Authority, a regulator of communication services provision in Ghana, will be informed about the performances of the ISPs along five performance criteria. This is expected to aid in their regulatory functions. © 2018, Emerald Publishing Limited.;
Liu F.-L., Zhang B.-W., Ciucci D., Wu W.-Z., Min F.;A comparison study of similarity measures for covering-based neighborhood classifiers;2018;Information Sciences;448-449;;;1;17;;;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043765914&doi=10.1016%2fj.ins.2018.03.030&partnerID=40&md5=5fa932ae39cff5efecad587a5eb60e12;In data mining, neighborhood classifiers are valid not only for numeric data but also symbolic data. The key issue for a neighborhood classifier is how to measure the similarity between two instances. In this paper, we compare six similarity measures, Overlap, Eskin, occurrence frequency (OF), inverse OF (IOF), Goodall3, and Goodall4, for symbolic data under the framework of a covering-based neighborhood classifier. In the training stage, a covering of the universe is built based on the given similarity measure. Then a covering reduction algorithm is used to remove some of these covering blocks and determine the representatives. In the testing stage, the similarities between all unlabeled instances and representatives are computed. The closest representative or a few representatives determine the predicted class label of the unlabeled instance. We compared the six similarity measures in experiments on 15 University of California-Irvine (UCI) datasets. The results demonstrate that although no measure dominated the others in all scenarios, some measures had consistently high performance. The covering-based neighborhood classifier with appropriate similarity measures, such as Overlap, IOF, and OF, was better than ID3, C4.5, and the Na?ve Bayes classifiers. © 2018 Elsevier Inc.;
Gómez-García E., Azevedo J.C., Pérez-Rodríguez F.;A compiled project and open-source code to generate web-based forest modelling simulators;2018;Computers and Electronics in Agriculture;147;;;1;5;;;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042192826&doi=10.1016%2fj.compag.2018.02.010&partnerID=40&md5=990ea9d4b4e2428f7a42dc8978c0a365;Sustainable forest management requires decision support systems to evaluate possible scenarios and anticipate the consequences of decisions. Forest modellers typically develop complex systems of equations to predict the behaviour of forests which makes the use of forest models difficult for end-users in general, affecting transfer of knowledge and technology. To overcome these difficulties and facilitate their practical use, models can be integrated into software to generate user-friendly forest simulators. In this paper we introduce and describe ForestMTIS, a cloud computing compiled and editable open-source project to generate forest simulators which was developed for statistical, non-spatial, deterministic, disaggregated, single species even-aged stand growth and yield models. We demonstrate the use of ForestMTIS based on the development of FlorNExT® its first practical application, based on a collaborative approach to make growth and yield modelling and sustainable forest management available to a large community of users in the Northeast of Portugal. © 2018 Elsevier B.V.;
Gómez-García E., Azevedo J.C., Pérez-Rodríguez F.;A compiled project and open-source code to generate web-based forest modelling simulators;2018;Computers and Electronics in Agriculture;147;;;1;5;;;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042192826&doi=10.1016%2fj.compag.2018.02.010&partnerID=40&md5=990ea9d4b4e2428f7a42dc8978c0a365;Sustainable forest management requires decision support systems to evaluate possible scenarios and anticipate the consequences of decisions. Forest modellers typically develop complex systems of equations to predict the behaviour of forests which makes the use of forest models difficult for end-users in general, affecting transfer of knowledge and technology. To overcome these difficulties and facilitate their practical use, models can be integrated into software to generate user-friendly forest simulators. In this paper we introduce and describe ForestMTIS, a cloud computing compiled and editable open-source project to generate forest simulators which was developed for statistical, non-spatial, deterministic, disaggregated, single species even-aged stand growth and yield models. We demonstrate the use of ForestMTIS based on the development of FlorNExT® its first practical application, based on a collaborative approach to make growth and yield modelling and sustainable forest management available to a large community of users in the Northeast of Portugal. © 2018 Elsevier B.V.;
Chae B.;A complexity theory approach to IT-enabled services (IESs) and service innovation: Business analytics as an illustration of IES;2014;Decision Support Systems;57;1;;1;10;;20;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84892364312&doi=10.1016%2fj.dss.2013.07.005&partnerID=40&md5=96c4f7dfd2361b09167b75f46b35c7ea;While firms view services as the main source of their revenue and competitive advantage, understanding of service and service innovation is limited. This lack of understanding is especially significant in IT-Enabled Services (IESs) and IES innovation. Much work is needed to understand the contemporary trend of integrating diverse material and social resources to address complex organizational and individual needs. This article proposes a novel framework for IES and IES innovation and develops propositions and implications for research and practice. This work draws upon the tenet of complexity theory and conceptualizes IES as complex adaptive systems (CAS), with such properties and behaviors as diverse adaptive elements, nonlinear interaction, self-organization, and adaptive learning, and IES innovation as a co-evolutionary process of variation, selection, and retention (VSR). The proposed framework is illustrated using business analytics (BA) as a new kind of decision support service (DSS) throughout this paper. Several propositions are developed. Finally, we present a discussion and implications. © 2013 Elsevier B.V.;
Kung S.Y.;A Compressive Privacy approach to Generalized Information Bottleneck and Privacy Funnel problems;2018;Journal of the Franklin Institute;355;4;;1846;1872;;;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026385440&doi=10.1016%2fj.jfranklin.2017.07.002&partnerID=40&md5=ccc83234ddb4b2501aa32d662d54dad4;This paper explores a Compressive Privacy (CP) methodology for optimal tradeoff between utility gain and privacy loss. CP represents a dimension-reduced subspace design of optimally desensitized query that may be safely shared with the public. Built upon the information and estimation theory, this paper proposes a “differential mutual information” (DMI) criterion to safeguard the privacy protection (PP). Algorithmically, DMI-optimal solutions can be derived via the Discriminant Component Analysis (DCA). Moreover, DCA has two machine learning variants (one in the original space and another is the kernel space) good for supervised learning applications. By extending the notion of DMI to the utility gain and privacy loss, CP unifies the conventional Information Bottleneck (IB) and Privacy Funnel (PF) and lead to two constrained optimizers, named Generalized Information Bottleneck (GIB) and Generalized Privacy Funnel (GPF). In the supervised learning environments, DCA can be further extended to a DUCA machine learning variant to reach an optimal tradeoff between utility gain and privacy loss. Finally, for fast convergence, a golden-section iterative method is developed particularly for solving the two constrained optimization problems: GIB and GPF. © 2017;
Kabir E., Siuly, Cao J., Wang H.;A computer aided analysis scheme for detecting epileptic seizure from EEG data;2018;International Journal of Computational Intelligence Systems;11;1;;663;671;;;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045662327&doi=10.2991%2fijcis.11.1.51&partnerID=40&md5=aaf9e07bec403ad07610ff2314a858a0;"This paper presents a computer aided analysis system for detecting epileptic seizure from electroencephalogram (EEG) signal data. As EEG recordings contain a vast amount of data, which is heterogeneous with respect to a time-period, we intend to introduce a clustering technique to discover different groups of data according to similarities or dissimilarities among the patterns. In the proposed methodology, we use K-means clustering for partitioning each category EEG data set (e.g. healthy; epileptic seizure) into several clusters and then extract some representative characteristics from each cluster. Subsequently, we integrate all the features from all the clusters in one feature set and then evaluate that feature set by three well-known machine learning methods: Support Vector Machine (SVM), Naive bayes and Logistic regression. The proposed method is tested by a publicly available benchmark database: ‘Epileptic EEG database’. The experimental results show that the proposed scheme with SVM classifier yields overall accuracy of 100% for classifying healthy vs epileptic seizure signals and outperforms all the recent reported existing methods in the literature. The major finding of this research is that the proposed K-means clustering based approach has an ability to efficiently handle EEG data for the detection of epileptic seizure. © 2018, the Authors.";
Kharazmi P., Zheng J., Lui H., Jane Wang Z., Lee T.K.;A Computer-Aided Decision Support System for Detection and Localization of Cutaneous Vasculature in Dermoscopy Images Via Deep Feature Learning;2018;Journal of Medical Systems;42;2;33;;;;;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040375669&doi=10.1007%2fs10916-017-0885-2&partnerID=40&md5=f9d6c38fc7dc3a300d466a2efbcfb683;"Vascular structures of skin are important biomarkers in diagnosis and assessment of cutaneous conditions. Presence and distribution of lesional vessels are associated with specific abnormalities. Therefore, detection and localization of cutaneous vessels provide critical information towards diagnosis and stage status of diseases. However, cutaneous vessels are highly variable in shape, size, color and architecture, which complicate the detection task. Considering the large variability of these structures, conventional vessel detection techniques lack the generalizability to detect different vessel types and require separate algorithms to be designed for each type. Furthermore, such techniques are highly dependent on precise hand-crafted features which are time-consuming and computationally inefficient. As a solution, we propose a data-driven feature learning framework based on stacked sparse auto-encoders (SSAE) for comprehensive detection of cutaneous vessels. Each training image is divided into small patches of either containing or non-containing vasculature. A multilayer SSAE is designed to learn hidden features of the data in hierarchical layers in an unsupervised manner. The high-level learned features are subsequently fed into a classifier which categorizes each patch into absence or presence of vasculature and localizes vessels within the lesion. Over a test set of 3095 patches derived from 200 images, the proposed framework demonstrated superior performance of 95.4% detection accuracy over a variety of vessel patterns; outperforming other techniques by achieving the highest positive predictive value of 94.7%. The proposed Computer-Aided Diagnosis (CAD) framework can serve as a decision support system assisting dermatologists for more accurate diagnosis, especially in teledermatology applications in remote areas. © 2018, Springer Science+Business Media, LLC, part of Springer Nature.";
Partheeban N., Ali A.M.;A conceptual analysis: Adaptive learning environment using AI techniques;2018;International Journal of Pure and Applied Mathematics;118;Special Issue 10;;353;362;;;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044870895&doi=10.12732%2fijpam.v118i10.76&partnerID=40&md5=3980e3aea2e4dff84cea8e4339842cda;In this paper, we exhibit a hands-on implementation of a Multi User specialized research center that involves Artificial Intelligence (AI), Share-it (SI), Bluetooth (BT) procedures. The main aim is to develop Mlearning environment where students can work in a personalized manner. Applying BT and SI abilities in m-learning domain can be separated into a classroom and utilized by a various learners concurrently. The students performance can be managed by various methods for AI techniques (Scheduling , planning and master frameworks). Incorporating these advances, the entire framework will have the capacity to identify every client, categorize his/her work and review his/her outcomes without or little instructor intercession. However, the instructor will be accounted about the understudy activities and will be prompted when the circumstance requires it. © 2018 Academic Press. All rights reserved.;
Plachkinova M., Vo A., Bhaskar R., Hilton B.;A conceptual framework for quality healthcare accessibility: a scalable approach for big data technologies;2018;Information Systems Frontiers;20;2;;289;302;;3;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84996956043&doi=10.1007%2fs10796-016-9726-y&partnerID=40&md5=330244d28591d802749547c0855a52df;Healthcare accessibility research has been of growing interest for scholars and practitioners. This manuscript classifies prior studies on the Floating Catchment Area methodologies, a prevalent class of methodologies that measure healthcare accessibility, and presents a framework that conceptualizes accessibility computation. We build the Floating Catchment Method General Framework as an IT artifact, following best practices in Design Science Research. We evaluate the utility of our framework by creating an instantiation, as an algorithm, and test it with large healthcare data sets from California. We showcase the practical application of the artifact and address the pressing issue of access to quality healthcare. This example also serves as a prototype for Big Data Analytics, as it presents opportunities to scale the analysis vertically and horizontally. In order for researchers to perform high impact studies and make the world a better place, an overarching framework utilizing Big Data Analytics should be seriously considered. © 2016, Springer Science+Business Media New York.;
